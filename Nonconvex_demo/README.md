# Non-convex Demo

Applying both gradient descent and Newton's method on a non-convex problem

Gradient descent is slowed down by saddle points, but it is unlikely to converge to them.

Newton's method, on the other hand, often converges to saddle points and even local max.

See the demo script:

[Demo in HTML format](http://htmlpreview.github.io/?https://github.com/stephenbeckr/CambridgeOptimisationCourse/blob/master/Nonconvex_demo/nonconvex_example_2D.html)
(this link uses the nice htmlpreview.github.io website; if you just click the raw html file, it will not render)
